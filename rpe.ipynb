{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from timm.models.layers import trunc_normal_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords_flatten.shape:  torch.Size([2, 9])\n",
      "coords_flatten.shape:  torch.Size([2, 9, 1])\n",
      "relative_coords.shape:  torch.Size([2, 9, 9])\n",
      "relative_coords values:  tensor(0) tensor(0)\n",
      "relative_coords values after:  tensor(10) tensor(2)\n",
      "tensor([[12, 11, 10,  7,  6,  5,  2,  1,  0],\n",
      "        [13, 12, 11,  8,  7,  6,  3,  2,  1],\n",
      "        [14, 13, 12,  9,  8,  7,  4,  3,  2],\n",
      "        [17, 16, 15, 12, 11, 10,  7,  6,  5],\n",
      "        [18, 17, 16, 13, 12, 11,  8,  7,  6],\n",
      "        [19, 18, 17, 14, 13, 12,  9,  8,  7],\n",
      "        [22, 21, 20, 17, 16, 15, 12, 11, 10],\n",
      "        [23, 22, 21, 18, 17, 16, 13, 12, 11],\n",
      "        [24, 23, 22, 19, 18, 17, 14, 13, 12]])\n",
      "coords_flatten.shape:  torch.Size([2, 9])\n",
      "coords_flatten.shape:  torch.Size([2, 9, 1])\n",
      "relative_coords.shape:  torch.Size([2, 9, 9])\n",
      "relative_coords values:  tensor(0) tensor(0)\n",
      "relative_coords values after:  tensor(10) tensor(2)\n",
      "tensor([12, 11, 10,  7,  6,  5,  2,  1,  0, 13, 12, 11,  8,  7,  6,  3,  2,  1,\n",
      "        14, 13, 12,  9,  8,  7,  4,  3,  2, 17, 16, 15, 12, 11, 10,  7,  6,  5,\n",
      "        18, 17, 16, 13, 12, 11,  8,  7,  6, 19, 18, 17, 14, 13, 12,  9,  8,  7,\n",
      "        22, 21, 20, 17, 16, 15, 12, 11, 10, 23, 22, 21, 18, 17, 16, 13, 12, 11,\n",
      "        24, 23, 22, 19, 18, 17, 14, 13, 12])\n"
     ]
    }
   ],
   "source": [
    "def get_relative_position_index(win_h: int, win_w: int) -> torch.Tensor:\n",
    "    \"\"\"Function to generate pair-wise relative position index for each token inside the window.\n",
    "        Taken from Timms Swin V1 implementation.\n",
    "    Args:\n",
    "        win_h (int): Window/Grid height.\n",
    "        win_w (int): Window/Grid width.\n",
    "    Returns:\n",
    "        relative_coords (torch.Tensor): Pair-wise relative position indexes [height * width, height * width].\n",
    "    \"\"\"\n",
    "    coords = torch.stack(torch.meshgrid([torch.arange(win_h), torch.arange(win_w)]))\n",
    "    # print(coords.shape)\n",
    "    coords_flatten = torch.flatten(coords, 1)\n",
    "    print('coords_flatten.shape: ', coords_flatten.shape)\n",
    "    print('coords_flatten.shape: ', coords_flatten[:,:,None].shape)\n",
    "    relative_coords = coords_flatten[:, :, None] - coords_flatten[:, None, :]\n",
    "    print('relative_coords.shape: ', relative_coords.shape)\n",
    "    relative_coords = relative_coords.permute(1, 2, 0).contiguous()\n",
    "    print('relative_coords values: ', relative_coords[0, 0, 0], relative_coords[0, 0, 1])\n",
    "    relative_coords[:, :, 0] += win_h - 1\n",
    "    relative_coords[:, :, 1] += win_w - 1\n",
    "    relative_coords[:, :, 0] *= 2 * win_w - 1\n",
    "    \n",
    "    print('relative_coords values after: ', relative_coords[0, 0, 0], relative_coords[0, 0, 1])\n",
    "    return relative_coords.sum(-1)\n",
    "\n",
    "print(get_relative_position_index(3, 3))\n",
    "print(get_relative_position_index(3, 3).view(-1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0018],\n",
       "        [ 0.0313],\n",
       "        [-0.0024],\n",
       "        [ 0.0076],\n",
       "        [ 0.0075],\n",
       "        [-0.0005],\n",
       "        [-0.0253],\n",
       "        [-0.0023],\n",
       "        [-0.0064],\n",
       "        [-0.0229],\n",
       "        [ 0.0166],\n",
       "        [-0.0106],\n",
       "        [ 0.0071],\n",
       "        [ 0.0084],\n",
       "        [ 0.0272],\n",
       "        [ 0.0013],\n",
       "        [ 0.0029],\n",
       "        [-0.0019],\n",
       "        [ 0.0119],\n",
       "        [-0.0239],\n",
       "        [ 0.0146],\n",
       "        [-0.0215],\n",
       "        [ 0.0016],\n",
       "        [ 0.0075],\n",
       "        [-0.0018]], requires_grad=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * 3 - 1) * (2 * 3 - 1), 1)\n",
    "        )\n",
    "trunc_normal_(relative_position_bias_table, std=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords_flatten.shape:  torch.Size([2, 9])\n",
      "coords_flatten.shape:  torch.Size([2, 9, 1])\n",
      "relative_coords.shape:  torch.Size([2, 9, 9])\n",
      "relative_coords values:  tensor(0) tensor(0)\n",
      "relative_coords values after:  tensor(10) tensor(2)\n"
     ]
    }
   ],
   "source": [
    "relative_position_index = get_relative_position_index(3, 3).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 9, 9])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_position_bias_table[relative_position_index].view(9, 9, -1).permute(2, 0, 1).contiguous().unsqueeze(0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords_flatten.shape:  torch.Size([2, 9])\n",
      "coords_flatten.shape:  torch.Size([2, 9, 1])\n",
      "relative_coords.shape:  torch.Size([2, 9, 9])\n",
      "relative_coords values:  tensor(0) tensor(2)\n",
      "tensor([[12, 11, 10,  7,  6,  5,  2,  1,  0],\n",
      "        [13, 12, 11,  8,  7,  6,  3,  2,  1],\n",
      "        [14, 13, 12,  9,  8,  7,  4,  3,  2],\n",
      "        [17, 16, 15, 12, 11, 10,  7,  6,  5],\n",
      "        [18, 17, 16, 13, 12, 11,  8,  7,  6],\n",
      "        [19, 18, 17, 14, 13, 12,  9,  8,  7],\n",
      "        [22, 21, 20, 17, 16, 15, 12, 11, 10],\n",
      "        [23, 22, 21, 18, 17, 16, 13, 12, 11],\n",
      "        [24, 23, 22, 19, 18, 17, 14, 13, 12]])\n"
     ]
    }
   ],
   "source": [
    "print(get_relative_position_index(3, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0],\n",
       "         [1, 1, 1],\n",
       "         [2, 2, 2]],\n",
       "\n",
       "        [[0, 1, 2],\n",
       "         [0, 1, 2],\n",
       "         [0, 1, 2]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "win_h, win_w = 3, 3\n",
    "torch.stack(torch.meshgrid([torch.arange(win_h), torch.arange(win_w)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
