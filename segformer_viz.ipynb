{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working dirC:\\Users\\abjawad\\Documents\\GitHub\\local-attention-model\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "currentFolder = os.path.abspath('')\n",
    "try:\n",
    "    sys.path.remove(str(currentFolder))\n",
    "except ValueError: # Already removed\n",
    "    pass\n",
    "\n",
    "projectFolder = 'C:/Users/abjawad/Documents/GitHub/local-attention-model'\n",
    "sys.path.append(str(projectFolder))\n",
    "os.chdir(projectFolder)\n",
    "print( f\"current working dir{os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abjawad\\.conda\\envs\\pt_cuda\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from  torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "from models.builder import EncoderDecoder as segmodel\n",
    "from dataloader.cfg_defaults import get_cfg_defaults\n",
    "from utils.lr_policy import WarmUpPolyLR\n",
    "from utils.init_func import init_weight, group_weight\n",
    "from config_cityscapes import *\n",
    "import yaml\n",
    "import os\n",
    "from dataloader.cityscapes_dataloader import CityscapesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = 'C:/Users/abjawad/Documents/GitHub/local-attention-model/dataloader/cityscapes_rgbd_config.yaml'\n",
    "# with open(config_path) as info:\n",
    "#     info_dict = yaml.load(info, Loader=yaml.FullLoader)\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(config_path)\n",
    "cfg.freeze()\n",
    "\n",
    "data_mean = [0.291,  0.329,  0.291]\n",
    "data_std = [0.190,  0.190,  0.185]\n",
    "\n",
    "# torch.cuda.set_per_process_memory_fraction(0.3, device=0)\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:1024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using RGB input\n",
      "Using RGB input\n",
      "Found 2975 train images\n",
      "total train: 2975 t_iteration:743\n",
      "Using RGB input\n",
      "Using RGB input\n",
      "Found 500 val images\n",
      "total val: 500 v_iteration:500\n"
     ]
    }
   ],
   "source": [
    "cityscapes_train = CityscapesDataset(cfg, split='train')\n",
    "train_loader = DataLoader(cityscapes_train, batch_size=4, shuffle=True, num_workers=4, drop_last=True)\n",
    "print(f'total train: {len(cityscapes_train)} t_iteration:{len(train_loader)}')\n",
    "cityscapes_val = CityscapesDataset(cfg, split='val')\n",
    "val_loader = DataLoader(cityscapes_val, batch_size=1, shuffle=False, num_workers=4)\n",
    "print(f'total val: {len(cityscapes_val)} v_iteration:{len(val_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Create a folder named \"out\" in the current directory\n",
    "output_folder = \"out\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "data_mean = [0.291, 0.329, 0.291]\n",
    "data_std = [0.190, 0.190, 0.185]\n",
    "\n",
    "# Loop to plot and save 200 random images\n",
    "for i in range(10):\n",
    "    img = cityscapes_train.__getitem__(i)  # Replace with your dataset access method\n",
    "    print(img['image'].shape, type(img['image']))\n",
    "    # Unnormalize the image\n",
    "    img = img['image'].numpy()\n",
    "    img = img.transpose((1, 2, 0))\n",
    "    img *= data_std\n",
    "    img += data_mean\n",
    "\n",
    "    # Plot the image (optional)\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis('off')  # Turn off axes for visualization\n",
    "    # plt.savefig(os.path.join(output_folder, f\"image_{i}.png\"), bbox_inches='tight', pad_inches=0)\n",
    "    # plt.close()\n",
    "    break\n",
    "# exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one image \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img = cityscapes_train[0]\n",
    "print(img['image'].shape)\n",
    "print(img['label'].shape)\n",
    "\n",
    "# unnormalize\n",
    "img = img['image'].numpy()\n",
    "img = img.transpose((1,2,0))\n",
    "img *= data_std\n",
    "img += data_mean\n",
    "# img = img.astype(np.uint8)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "label = img['label']\n",
    "plt.imshow(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='mean', ignore_index=config.background)\n",
    "BatchNorm2d = nn.BatchNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=segmodel(cfg=config, criterion=criterion, norm_layer=BatchNorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = []\n",
    "params_list = group_weight(params_list, model, BatchNorm2d, config.lr)        \n",
    "optimizer = torch.optim.AdamW(params_list, lr=config.lr, betas=(0.9, 0.999), weight_decay=config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iteration = config.nepochs * config.niters_per_epoch\n",
    "lr_policy = WarmUpPolyLR(config.lr, config.lr_power, total_iteration, config.niters_per_epoch * config.warm_up_epoch)\n",
    "print(f'lr_policy:{vars(lr_policy)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = nn.DataParallel(model, device_ids = config.device_ids)\n",
    "# model.to(f'cuda:{model.device_ids[0]}', non_blocking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "# images shape torch.Size([4, 3, 1024, 1024])\n",
    "# gts shape torch.Size([4, 1024, 1024])\n",
    "\n",
    "# create a random ([4, 3, 1024, 1024]) tensor\n",
    "images = torch.rand(4, 3, 256, 256)\n",
    "\n",
    "# create a random ([4, 1024, 1024]) tensor\n",
    "gts = torch.randint(0, 19, (4, 256, 256))\n",
    "\n",
    "loss, out = model(images, gts)\n",
    "\n",
    "print('loss', loss)\n",
    "print('out', out.shape)\n",
    "\n",
    "# make no scaling\n",
    "# make_dot(loss, params=dict(model.named_parameters())).render(\"attached\", format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 2):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    sum_loss = 0\n",
    "    m_iou_batches = 0\n",
    "    for idx, sample in enumerate(train_loader):\n",
    "        imgs = sample['image']\n",
    "        gts = sample['label']\n",
    "        imgs = imgs.to(f'cuda:{model.device_ids[0]}', non_blocking=True)\n",
    "        gts = gts.to(f'cuda:{model.device_ids[0]}', non_blocking=True)  \n",
    "\n",
    "        print('images shape', imgs.shape)\n",
    "        print('gts shape', gts.shape)\n",
    "        # loss, out = model(imgs, gts)\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        # sum_loss += loss\n",
    "        # print(f'epoch:{epoch} iteration:{idx} loss:{loss}')\n",
    "        break\n",
    "    # print(f'epoch:{epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "input_size = (2, 19200, 32)\n",
    "# device='meta' -> no memory is consumed for visualization\n",
    "model_graph = draw_graph(model, input_size=input_size, device='meta')\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Assuming you have already created and loaded your 'model'\n",
    "model = segmodel(cfg=config, criterion=criterion, norm_layer=BatchNorm2d)\n",
    "# Load the pretrained weights (if not already loaded)\n",
    "model.load_state_dict(torch.load('C:/Users/abjawad/Documents/GitHub/local-attention-model/pretrained/mit_b2.pth'))\n",
    "\n",
    "# Specify the input shape (e.g., (channels, height, width))\n",
    "input_shape = (4, 19200, 32)  # Adjust the input shape according to your data\n",
    "\n",
    "# Use torchsummary to display the model summary\n",
    "summary(model, input_size=input_shape, device='cpu')  # 'cpu' or 'cuda' depending on your device\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
